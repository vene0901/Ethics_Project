<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Recognition & Civil Liberties</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>

<header>
    <h1>Facial Recognition & Civil Liberties</h1>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About Us</a></li>
            <li class="dropdown">
                <a class="dropbtn" href="#">Impacts</a>
                <div class="dropdown-content">
                    <a href="#ethnic_names">Ethnic Names & Ethnicity</a>
                    <a href="#race">Race</a>
                    <a href="#facial_recognition">Facial Recognition</a>
                </div>
            </li>
            <li><a href="personal_experience.html">Personal Experience</a></li>
            <li><a href="#">Tools</a></li>
            <li><a href="#">Personal Experience</a></li>
            <li><a href="#">Feedback</a></li>
        </ul>
    </nav>
</header>

<main>
    <section id="facial_recognition" class="impact-section">
        <h2>Facial Recognition & Civil Liberties</h2>
        <p>Understanding the Impact: Facial recognition systems often exhibit biases against certain demographics, leading to misidentification and unjust consequences.
        </p>
        <p>Potential Consequences: Biased facial recognition can result in wrongful arrests, surveillance of marginalized communities, and erosion of privacy rights.
        </p>
        <p>Data & Insights:</p>
        <p>The American Civil Liberties Union (ACLU) took legal action against the widespread use of unreliable and biased facial recognition technology in Detroit. In a lawsuit filed on December 15, 2020, the ACLU highlighted the dangers of misidentification and wrongful arrests caused by flawed facial recognition systems (ACLU, 2020).</p>
        <p>Case study:</p>
        <p>In 2020, the American Civil Liberties Union (ACLU) reported a case where a Black man in Detroit was wrongfully arrested due to a flawed facial recognition match. The system misidentified him as a suspect in a shoplifting case, leading to his unjust detention. This incident underscores the dangers of relying on biased facial recognition technology, especially when it disproportionately affects marginalized communities.</p>
    </section>
</main>

</body>
</html>
